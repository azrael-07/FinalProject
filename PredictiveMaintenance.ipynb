{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025be8f8-0049-400b-8577-41ee2a01e752",
   "metadata": {},
   "source": [
    "# Predictive Maintanence\n",
    "Predictive maintenance is a technique that uses data analysis tools and techniques to detect anomalies in your operation and possible defects in equipment and processes so you can fix them before they result in failure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ede565",
   "metadata": {},
   "source": [
    "# Data Description¶\n",
    "There are 5 CSV files consisting of:\n",
    "\n",
    "***Telemetry Time Series Data (PdM_telemetry.csv)*** : It consists of hourly average of voltage, rotation, pressure, vibration collected from 100 machines for the year 2015.\n",
    "\n",
    "***Error (PdM_errors.csv)***: These are errors encountered by the machines while in operating condition. Since, these errors don't shut down the machines, these are not considered as failures. The error date and times are rounded to the closest hour since the telemetry data is collected at an hourly rate.\n",
    "\n",
    "***Maintenance (PdM_maint.csv)***: If a component of a machine is replaced, that is captured as a record in this table. Components are replaced under two situations:\n",
    "\n",
    "During the regular scheduled visit, the technician replaced it (Proactive Maintenance)\n",
    "A component breaks down and then the technician does an unscheduled maintenance to replace the component (Reactive Maintenance). This is considered as a failure and corresponding data is captured under Failures. Maintenance data has both 2014 and 2015 records. This data is rounded to the closest hour since the telemetry data is collected at an hourly rate.\n",
    "\n",
    "***Failures (PdM_failures.csv)**: Each record represents replacement of a component due to failure. This data is a subset of Maintenance data. This data is rounded to the closest hour since the telemetry data is collected at an hourly rate.\n",
    "\n",
    "***Metadata of Machines (PdM_Machines.csv)***: Model type & age of the Machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625a5f3-1066-485d-ac68-999d02b45cb9",
   "metadata": {},
   "source": [
    "Predictive Maintanence\n",
    "Predictive maintenance is a technique that uses data analysis tools and techniques to detect anomalies in your operation and possible defects in equipment and processes so you can fix them before they result in failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae924a-2455-4b1d-b726-5bb6e593c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anai\n",
    "from anai.preprocessing import Preprocessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1039884-95a5-411d-8d83-777078628d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_df = pd.read_csv('DATA/PdM_telemetry.csv')\n",
    "errors_df = pd.read_csv('DATA/PdM_errors.csv')\n",
    "maint_df = pd.read_csv('DATA/PdM_maint.csv')\n",
    "failures_df = pd.read_csv('DATA/PdM_failures.csv')\n",
    "machines_df = pd.read_csv('DATA/PdM_machines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b084c7f-61be-48c1-b255-ad9f18189f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [telemetry_df, maint_df, failures_df, errors_df]\n",
    "for df in tables:\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df.sort_values([\"datetime\", \"machineID\"], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594c357-6316-41b4-9ed5-5eac207394f1",
   "metadata": {},
   "source": [
    "# Data Insights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa627a-b651-4f26-b13d-1061f3336f2c",
   "metadata": {},
   "source": [
    "\n",
    "## Telemetry Data¶\n",
    "> This data consists of hourly average of voltage, rotation, pressure, vibration collected from 100 machines for the year 2015.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe752cf-5f8d-4a13-ac08-357a798d9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the Telemetry : {telemetry_df.shape}\")\n",
    "print(\"\\n\")\n",
    "telemetry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5280c-7d39-433e-9959-f00736418a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"No.Of Machine in the Telemetry : {telemetry_df.machineID.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb484c7-5210-479c-86e1-a7e408f233f4",
   "metadata": {},
   "source": [
    "### Missing Values in the Telemetry data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e227d6-bfa3-412f-8421-789438936a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_df.datetime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c87a2-c0f2-466f-aa41-aedcd860caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('missing Dates : ' , telemetry_df.datetime.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3ac224-2dd7-48d2-8141-159fc71476c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb233fb-ff66-43f2-8e81-d8564a3d0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_df.describe()  ##info on this is Required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a32bfa7",
   "metadata": {},
   "source": [
    "## Error Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620898ec",
   "metadata": {},
   "source": [
    "## Maintainance Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e458df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81333ac0",
   "metadata": {},
   "source": [
    "## Machine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the Machines Data: {machines_df.shape}\")\n",
    "print(\"\\n\")\n",
    "machines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256ec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c146fcfc",
   "metadata": {},
   "source": [
    "## Failure Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fae8fb3-5291-47ba-a881-50ebc3eaee39",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe635cf0-fef2-4669-bd71-a518aa46b248",
   "metadata": {},
   "source": [
    "## EDA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df28f2-cf40-453a-80bd-fa33283a6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features(source_df, target_df, feature_name):\n",
    "    '''\n",
    "    Create new features related to dates\n",
    "    \n",
    "    source_df : DataFrame consisting of the timestamp related feature\n",
    "    target_df : DataFrame where new features will be added\n",
    "    feature_name : Name of the feature of date type which needs to be decomposed.\n",
    "    '''\n",
    "    target_df.loc[:, 'year'] = source_df.loc[:, feature_name].dt.year.astype('uint16')\n",
    "    target_df.loc[:, 'month'] = source_df.loc[:, feature_name].dt.month.astype('uint8')\n",
    "    target_df.loc[:, 'quarter'] = source_df.loc[:, feature_name].dt.quarter.astype('uint8')\n",
    "    target_df.loc[:, 'weekofyear'] = source_df.loc[:, feature_name].dt.isocalendar().week.astype('uint8')\n",
    "    \n",
    "    target_df.loc[:, 'hour'] = source_df.loc[:, feature_name].dt.hour.astype('uint8')\n",
    "    \n",
    "    target_df.loc[:, 'day'] = source_df.loc[:, feature_name].dt.day.astype('uint8')\n",
    "    target_df.loc[:, 'dayofweek'] = source_df.loc[:, feature_name].dt.dayofweek.astype('uint8')\n",
    "    target_df.loc[:, 'dayofyear'] = source_df.loc[:, feature_name].dt.dayofyear.astype('uint8')\n",
    "    target_df.loc[:, 'is_month_start'] = source_df.loc[:, feature_name].dt.is_month_start\n",
    "    target_df.loc[:, 'is_month_end'] = source_df.loc[:, feature_name].dt.is_month_end\n",
    "    target_df.loc[:, 'is_quarter_start']= source_df.loc[:, feature_name].dt.is_quarter_start\n",
    "    target_df.loc[:, 'is_quarter_end'] = source_df.loc[:, feature_name].dt.is_quarter_end\n",
    "    target_df.loc[:, 'is_year_start'] = source_df.loc[:, feature_name].dt.is_year_start\n",
    "    target_df.loc[:, 'is_year_end'] = source_df.loc[:, feature_name].dt.is_year_end\n",
    "    \n",
    "    # This is of type object\n",
    "    target_df.loc[:, 'month_year'] = source_df.loc[:, feature_name].dt.to_period('M')\n",
    "    \n",
    "    return target_df\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram(data, x_column, color_column, title, nbins=1000, width=1000, height=600, log_x=False, log_y=False):\n",
    "    \"\"\"\n",
    "    Generates a Plotly histogram.\n",
    "    \"\"\"\n",
    "    fig = px.histogram(\n",
    "        data,\n",
    "        x=x_column,\n",
    "        color=color_column,\n",
    "        title=title,\n",
    "        nbins=nbins,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        log_x=log_x,\n",
    "        log_y=log_y\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title=x_column,\n",
    "        yaxis_title=\"Count\"\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_boxplot(data, x_column, y_column, title, width=1000, height=900, xaxis_title=None, yaxis_title=None):\n",
    "    \"\"\"\n",
    "    Generates a Plotly boxplot.\n",
    "\n",
    "   \n",
    "    \"\"\"\n",
    "    fig = px.box(\n",
    "        data,\n",
    "        x=x_column,\n",
    "        y=y_column,\n",
    "        title=title,\n",
    "        width=width,\n",
    "        height=height\n",
    "    )\n",
    "    \n",
    "    # Update layout with custom axis titles if provided\n",
    "    fig.update_layout(\n",
    "        xaxis_title=xaxis_title if xaxis_title else x_column,\n",
    "        yaxis_title=yaxis_title if yaxis_title else y_column\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "def plot_scatter(df, feature_x, feature_y, title=None, xlabel=None, ylabel=None, width=800, height=600):\n",
    "    \"\"\"\n",
    "    Create a scatter plot using Plotly.\n",
    "    \"\"\"\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=feature_x,\n",
    "        y=feature_y,\n",
    "        title=title,\n",
    "        width=width,\n",
    "        height=height\n",
    "    )\n",
    "    \n",
    "    # Update axis labels if provided\n",
    "    fig.update_layout(\n",
    "        xaxis_title=xlabel if xlabel else feature_x,\n",
    "        yaxis_title=ylabel if ylabel else feature_y\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23b25a-caf8-4225-81df-949a47ffa41b",
   "metadata": {},
   "source": [
    "## EDA On Telemetry Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833150b-8e31-4979-897e-20ffbd1c0f3d",
   "metadata": {},
   "source": [
    " Vibration of Machine1 for 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece4e6d-16df-4c5f-a15b-2a01cc62d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vib_machine_1 = telemetry_df[\n",
    "    telemetry_df.machineID == 1][[\"datetime\", \"vibration\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734ccb2-ac72-48b9-89fa-a306c7e720f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x = df_vib_machine_1['datetime'].values, y = df_vib_machine_1['vibration'].values ,title=\"Vibration of Machine 1\",template='plotly_dark')\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Vibration')\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b5d99-87ed-4d42-8c58-2b35ccf68332",
   "metadata": {},
   "source": [
    "Voltage for Machine1 for January Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928900f-0221-4022-b371-a3fefc90e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = telemetry_df.loc[(telemetry_df['machineID'] == 1) &\n",
    "                        (telemetry_df['datetime'] > pd.to_datetime('2015-01-01')) &\n",
    "                        (telemetry_df['datetime'] < pd.to_datetime('2015-02-01')), ['datetime', 'volt']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b72da3-40d9-4f3c-a74f-770e038325a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=plot_df['datetime'].values, y=plot_df['volt'].values, title='Voltage over time', template='plotly_dark')\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Voltage')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09953724-ad69-44f9-9a11-85d27a55f8eb",
   "metadata": {},
   "source": [
    "Machine2 Voltage First Two weeks of 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3b0b5-4d5e-4770-95a7-eb3b2eb88e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vib_machine_1 = telemetry_df[\n",
    "    (telemetry_df.machineID == 2) & (\n",
    "        telemetry_df.datetime.dt.isocalendar().week.isin(\n",
    "            [1, 2, 3]))][[\"datetime\", \"volt\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385a25b-8718-455f-b9db-e5f9d4f054c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=df_vib_machine_1['datetime'].values, y=df_vib_machine_1['volt'].values, title='Voltage over time', template='plotly_dark')\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Voltage')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b936943-7319-48a0-9c27-e869106d620c",
   "metadata": {},
   "source": [
    "Plot the distribution of voltage across various months. Ideally there should be some amount seasonality in the data¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d51eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_df = create_date_features(telemetry_df, telemetry_df, \"datetime\")\n",
    "telemetry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05cb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_df = create_date_features(telemetry_df, telemetry_df, \"datetime\")\n",
    "telemetry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a491b3-bdf6-4934-9c1d-7978ab102b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_df['month_year'] = telemetry_df['month_year'].astype(str)\n",
    "\n",
    "fig = plot_boxplot(\n",
    "    telemetry_df,\n",
    "    x_column=\"volt\",\n",
    "    y_column=\"month_year\",\n",
    "    title=\"Distribution of volt by month_year\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aff90fa",
   "metadata": {},
   "source": [
    "It shows the voltage across Machines are not varying over month.\n",
    "\n",
    "We can ignore the entry for 2016 since we only have data for one day in 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b55cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = px.box(\n",
    "    telemetry_df[telemetry_df.machineID == 80], \n",
    "    x=\"volt\",  # Horizontal axis\n",
    "    y=\"month_year\",  # Grouping variable\n",
    "    title=\"Distribution of volt by month_year\",\n",
    "    width=1000,  # Adjust width (optional)\n",
    "    height=900   # Adjust height (optional)\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"volt\", \n",
    "    yaxis_title=\"month_year\"\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_histogram(\n",
    "    telemetry_df,\n",
    "    x_column=\"volt\",\n",
    "    color_column=\"month_year\",\n",
    "    title=\"Distribution of volt\",\n",
    "    nbins=1000\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff745f7",
   "metadata": {},
   "source": [
    "Thank you for sharing the histogram output! Here’s an analysis of the provided plot:\n",
    "\n",
    "Observations:\n",
    "\n",
    "\t1.\tOverall Distribution (Shape):\n",
    "\t•\tThe volt values exhibit a bell-shaped curve, which is indicative of a normal distribution. This suggests that most of the volt values are clustered around the mean, with fewer occurrences at the extremes.\n",
    "\t2.\tSpread Across month_year:\n",
    "\t•\tEach month_year is represented by a different color in the stacked histogram.\n",
    "\t•\tThere is a consistent distribution across months; no month appears to deviate significantly in terms of the volt distribution’s central tendency or spread.\n",
    "\t•\tAll months seem to have similar peak counts, with most data points centered around volt values between 160 and 180.\n",
    "\t\n",
    "\n",
    "Insights:\n",
    "\n",
    "\t1.\tConsistency Over Time:\n",
    "\t•\tThe near-identical distributions across months suggest that the volt readings are stable over time. This could indicate that the monitored system operates consistently, with no drastic changes or anomalies month-to-month.\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bb049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name in ['rotate', 'pressure', 'vibration']:\n",
    "    fig  =plot_histogram(telemetry_df, x_column=name, color_column=\"month_year\",  title=f\"Distribution of {name}\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cd988",
   "metadata": {},
   "source": [
    "Observations about Telemetry Data¶\n",
    "1. This may be synthetically generated data distributed between 1st Jan 2015 to 1st Jan 2016.\n",
    "2. Each row represents the state of a machine on a particular hour. Voltage, vibration, pressure & rotation of a machine have been averaged hourly.\n",
    "3. There are 100 unique Machines.\n",
    "4. There are no duplicates or missing values in the dataset.\n",
    "The four parameters voltage, vibration, pressure & rotation are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e482d61",
   "metadata": {},
   "source": [
    "## EDA on Machine Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634df30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_boxplot(\n",
    "    machines_df,\n",
    "    x_column=\"age\",\n",
    "    y_column=\"model\",\n",
    "    title=\"Distribution of age by model\",\n",
    "   \n",
    "    height = 400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d4934a",
   "metadata": {},
   "source": [
    "The age of the Machines is distributed between 0 to 20. The median age is to ~12.5. There are no outliers. Another indication that this is a synthetic data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DF with number of errors, maintenance records and failure records across machines\n",
    "\n",
    "# Create a DF consisting of number of erros across Machines\n",
    "erros_across_machine = errors_df.groupby(\"machineID\").size()\n",
    "erros_across_machine = pd.DataFrame(erros_across_machine, columns=[\"num_errors\"]).reset_index()\n",
    "\n",
    "machines_errors_df = pd.merge(machines_df, erros_across_machine, how='left', on=\"machineID\")\n",
    "\n",
    "# Create a DF consisting of number of maintenance records across Machines\n",
    "maint_across_machine = maint_df.groupby(\"machineID\").size()\n",
    "maint_across_machine = pd.DataFrame(maint_across_machine, columns=[\"num_maint\"]).reset_index()\n",
    "\n",
    "machines_errors_df = pd.merge(machines_errors_df, maint_across_machine, how='left', on=\"machineID\")\n",
    "\n",
    "# Create a DF consisting of number of failure records across Machines\n",
    "failure_across_machine = failures_df.groupby(\"machineID\").size()\n",
    "failure_across_machine = pd.DataFrame(failure_across_machine, columns=[\"num_failure\"]).reset_index()\n",
    "\n",
    "machines_errors_df = pd.merge(machines_errors_df, failure_across_machine, how='left', on=\"machineID\")\n",
    "\n",
    "machines_errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scatter(\n",
    "    df=machines_errors_df,\n",
    "    feature_x=\"age\",\n",
    "    feature_y=\"num_errors\",\n",
    "    title=\"Age vs Number of Errors\",\n",
    "    xlabel=\"Age\",\n",
    "    ylabel=\"Number of Errors\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c6d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scatter(\n",
    "    df=machines_errors_df,\n",
    "    feature_x=\"age\",\n",
    "    feature_y=\"num_maint\",\n",
    "    title=\"Age vs Number of Maintainance Records\",\n",
    "    xlabel=\"Age\",\n",
    "    ylabel=\"Number of Maintainance\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc95546",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scatter(\n",
    "    df=machines_errors_df,\n",
    "    feature_x=\"age\",\n",
    "    feature_y=\"num_failure\",\n",
    "    title=\"Age vs Number of Failure Records\",\n",
    "    xlabel=\"Age\",\n",
    "    ylabel=\"Number of Failure\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6543f1",
   "metadata": {},
   "source": [
    "From the above three plots, it appears only Number of Failures is slightly correlated with Age.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9fad47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd3fe5ba",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd0a57",
   "metadata": {},
   "source": [
    "### Identifying Lag Features from Telemetry Data on a window of 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0044b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "fields = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry_df,\n",
    "                               index='datetime',\n",
    "                               columns='machineID',\n",
    "                               values=col).resample('3H', closed='left', label='right').mean().unstack())\n",
    "telemetry_mean_3h = pd.concat(temp, axis=1)\n",
    "telemetry_mean_3h.columns = [i + 'mean_3h' for i in fields]\n",
    "telemetry_mean_3h.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "temp = []\n",
    "\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry_df,\n",
    "                               index='datetime',\n",
    "                               columns='machineID',\n",
    "                               values=col).resample('3H', closed='left', label='right').std().unstack())\n",
    "telemetry_sd_3h = pd.concat(temp, axis=1)\n",
    "telemetry_sd_3h.columns = [i + 'sd_3h' for i in fields]\n",
    "telemetry_sd_3h.reset_index(inplace=True)\n",
    "\n",
    "telemetry_mean_3h.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2dab67",
   "metadata": {},
   "source": [
    "\t•\tEach row represents a 3-hour time interval.\n",
    "\t•\tEach column corresponds to a specific machineID.\n",
    "\t•\tThe values are the mean of the selected column (col) for that machineID during that time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "fields = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry_df,\n",
    "    index='datetime',\n",
    "    columns='machineID',\n",
    "    values=col).resample('3H',closed='left',\n",
    "    label='right',).first().unstack().rolling(window=24, center=False).mean())\n",
    "\n",
    "telemetry_mean_24h = pd.concat(temp, axis=1)\n",
    "telemetry_mean_24h.columns = [i + 'mean_24h' for i in fields]\n",
    "telemetry_mean_24h.reset_index(inplace=True)\n",
    "telemetry_mean_24h = telemetry_mean_24h.loc[-telemetry_mean_24h['voltmean_24h'].isnull()]\n",
    "\n",
    "temp = []\n",
    "fields = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry_df,\n",
    "    index='datetime',\n",
    "    columns='machineID',\n",
    "    values=col).resample('3H',\n",
    "    closed='left',\n",
    "    label='right',\n",
    "    ).first().unstack().rolling(window=24, center=False).std())\n",
    "    \n",
    "telemetry_sd_24h = pd.concat(temp, axis=1)\n",
    "telemetry_sd_24h.columns = [i + 'sd_24h' for i in fields]\n",
    "telemetry_sd_24h.reset_index(inplace=True)\n",
    "telemetry_sd_24h = telemetry_sd_24h.loc[-telemetry_sd_24h['voltsd_24h'].isnull()]\n",
    "\n",
    "telemetry_mean_24h.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f992e5c6",
   "metadata": {},
   "source": [
    "\tA loop iterates over each field in fields.\n",
    "\t•\tFor each field:\n",
    "\t•\tThe pd.pivot_table() function transforms the telemetry data to have machineID as columns and datetime as the index.\n",
    "\t•\tIt uses resample('3H') to downsample the data to 3-hour intervals, taking the first value in each interval (.first()).\n",
    "\t•\tThe unstacked data undergoes a rolling 24-hour window computation for the mean (rolling(window=24).mean())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f636ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_feat = pd.concat([telemetry_mean_3h,\n",
    "                            telemetry_sd_3h.iloc[:, 2:6],\n",
    "                            telemetry_mean_24h.iloc[:, 2:6],\n",
    "                            telemetry_sd_24h.iloc[:, 2:6]], axis=1).dropna()\n",
    "telemetry_feat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a76096",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199dbae7",
   "metadata": {},
   "source": [
    "### Identifying Lag Features from Error Data on a window of 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count = pd.get_dummies(errors_df.set_index('datetime')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8cc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count.columns = ['datetime', 'machineID',\n",
    "                       'error1', 'error2', 'error3', 'error4', 'error5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55860d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count = telemetry_df[['datetime', 'machineID']].merge(\n",
    "    error_count, on=['machineID', 'datetime'], how='left').fillna(0.0)\n",
    "error_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "fields = ['error%d' % i for i in range(1, 6)]\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(error_count,\n",
    "                                              index='datetime',\n",
    "                                              columns='machineID',\n",
    "                                              values=col).resample('3H',\n",
    "                                                                               closed='left',\n",
    "                                                                               label='right',\n",
    "                                                                               ).first().unstack().rolling(window=24, center=False).sum())\n",
    "error_count = pd.concat(temp, axis=1)\n",
    "error_count.columns = [i + 'count' for i in fields]\n",
    "error_count.reset_index(inplace=True)\n",
    "error_count = error_count.dropna()\n",
    "error_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea83900",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28f5b0",
   "metadata": {},
   "source": [
    "### Identifying Days Since Last Replacement using Maintainence on a window of 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da89559",
   "metadata": {},
   "source": [
    "The code is designed to calculate the metric “Days Since Last Replacement” for maintenance data using a rolling 24-hour window. The main goal is to determine how many days have passed since the last replacement or maintenance event for each machine, based on chronological timestamps.\n",
    "\n",
    "Key Steps and Functions Used:\n",
    "\n",
    "1.\tSorting the Data:\n",
    "The dataset is first sorted using functions like sort_values to ensure that timestamps for each machine are in ascending order. Sorting is critical for performing accurate chronological calculations.\n",
    "2.\tRolling Window Implementation:\n",
    "A 24-hour rolling window is applied using methods like rolling or custom filtering logic. This step identifies all maintenance events that occurred in the past 24 hours for each timestamp.\n",
    "3.\tCalculating Time Differences:\n",
    "The difference between the current timestamp and the most recent maintenance event is calculated. Functions like shift (to access the previous row) and arithmetic operations on datetime objects (e.g., timedelta) are used to derive the difference in days.\n",
    "4.\tHandling Missing Values:\n",
    "For timestamps where no maintenance occurred within the rolling window, methods like fillna or conditional logic (if-else) are used to handle missing data, ensuring the output remains consistent.\n",
    "5.\tUpdating the Dataset:\n",
    "The calculated “Days Since Last Replacement” is stored in a new column, enhancing the dataset for further analysis. This is typically done using assign or by directly adding a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb4528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_rep = pd.get_dummies(maint_df.set_index('datetime')).reset_index()\n",
    "comp_rep.columns = ['datetime', 'machineID',\n",
    "                    'comp1', 'comp2', 'comp3', 'comp4']\n",
    "\n",
    "comp_rep = telemetry_df[['datetime', 'machineID']].merge(comp_rep,\n",
    "                                                      on=['datetime',\n",
    "                                                          'machineID'],\n",
    "                                                      how='outer').fillna(0).sort_values(by=['machineID', 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = ['comp1', 'comp2', 'comp3', 'comp4']\n",
    "for comp in components:\n",
    "    comp_rep.loc[comp_rep[comp] < 1, comp] = None\n",
    "    comp_rep.loc[-comp_rep[comp].isnull(),\n",
    "                 comp] = comp_rep.loc[-comp_rep[comp].isnull(), 'datetime']\n",
    "    comp_rep[comp] = comp_rep[comp].fillna(method='ffill')\n",
    "\n",
    "comp_rep = comp_rep.loc[comp_rep['datetime'] > pd.to_datetime('2015-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in components:\n",
    "    comp_rep[comp] = (comp_rep[\"datetime\"] - pd.to_datetime(comp_rep[comp])) / np.timedelta64(1, \"D\") \n",
    "\n",
    "comp_rep.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_rep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352dfa3",
   "metadata": {},
   "source": [
    "### Machine Features: Descriptive Statistics about the Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feat = telemetry_feat.merge(\n",
    "    error_count, on=['datetime', 'machineID'], how='left')\n",
    "final_feat = final_feat.merge(\n",
    "    comp_rep, on=['datetime', 'machineID'], how='left')\n",
    "final_feat = final_feat.merge(machines_df, on=['machineID'], how='left')\n",
    "\n",
    "final_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338fcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ff8a9",
   "metadata": {},
   "source": [
    "# Label Construnction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_features = final_feat.merge(\n",
    "    failures_df, on=['datetime', 'machineID'], how='left')\n",
    "labeled_features = labeled_features.fillna(\n",
    "    method='bfill', limit=7)\n",
    "labeled_features = labeled_features.fillna('none')\n",
    "labeled_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_features.loc[labeled_features['failure'] == 'comp4'][:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80707648",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08681b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_dates = [[pd.to_datetime('2015-07-31 01:00:00'), pd.to_datetime('2015-08-01 01:00:00')],\n",
    "                   [pd.to_datetime('2015-08-31 01:00:00'),\n",
    "                    pd.to_datetime('2015-09-01 01:00:00')],\n",
    "                   [pd.to_datetime('2015-09-30 01:00:00'), pd.to_datetime('2015-10-01 01:00:00')]]\n",
    "\n",
    "test_results = []\n",
    "anai_models = []\n",
    "train_dfs = []\n",
    "for last_train_date, first_test_date in threshold_dates:\n",
    "    print('Training on %s to %s' % (last_train_date, first_test_date))\n",
    "    train_y = labeled_features.loc[labeled_features['datetime']\n",
    "                                   < last_train_date, 'failure']\n",
    "    train_X = pd.get_dummies(labeled_features.loc[labeled_features['datetime'] < last_train_date]\n",
    "                         .drop(['datetime', 'machineID', 'failure'], axis=1))\n",
    "    df = pd.concat([train_X, train_y], axis=1)\n",
    "    train_dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_dates = [[pd.to_datetime('2015-10-01 01:00:00'), pd.to_datetime('2015-10-31 01:00:00')],\n",
    "                   [pd.to_datetime('2015-11-01 01:00:00'),\n",
    "                    pd.to_datetime('2015-11-30 01:00:00')],\n",
    "                   [pd.to_datetime('2015-12-01 01:00:00'), pd.to_datetime('2016-01-01 01:00:00')]]\n",
    "\n",
    "\n",
    "test_dfs = []\n",
    "for last_train_date, first_test_date in threshold_dates:\n",
    "    print('Testing on %s to %s' % (last_train_date, first_test_date))\n",
    "    test_y = labeled_features.loc[labeled_features['datetime']\n",
    "                                   < last_train_date, 'failure']\n",
    "    test_X = pd.get_dummies(labeled_features.loc[labeled_features['datetime'] < last_train_date]\n",
    "                         .drop(['datetime', 'machineID', 'failure'], axis=1))\n",
    "    df = pd.concat([test_X, test_y], axis=1)\n",
    "    test_dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ef9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai1 = anai.run(target = 'failure', df = train_dfs[0], predictor = ['xgb', 'cat','lgbm', 'gbc', 'rfc'], ensemble = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936440af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai1.explain('shap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai1.explain('perm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea8a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform your labels (both for training and testing)\n",
    "y_test_numeric = label_encoder.fit_transform(test_y)\n",
    "\n",
    "# Display the mapping\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "print(y_test_numeric[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = ai1.predict(test_X)  # Predicted class labels\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_numeric, y_pred))\n",
    "\n",
    "# Accuracy Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = ai1.predict(test_X)  # Predicted class labels\n",
    "\n",
    "# Create Confusion Matrix\n",
    "cm = confusion_matrix(y_test_numeric, y_pred)\n",
    "labels = sorted(set(y_test_numeric))  # Unique class labels\n",
    "\n",
    "# Plot confusion matrix as a heatmap in Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=cm,\n",
    "    x=labels,  # Predicted labels\n",
    "    y=labels,  # Actual labels\n",
    "    colorscale='Blues',\n",
    "    hoverongaps=False,\n",
    "    texttemplate='%{z}',\n",
    "    textfont={\"size\": 10},\n",
    "    colorbar=dict(title=\"Count\")\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Confusion Matrix\",\n",
    "    xaxis=dict(title=\"Predicted Label\"),\n",
    "    yaxis=dict(title=\"Actual Label\"),\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9003b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai1.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8db269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the best model\n",
    "print(\"Best Classifier Name:\", ai1.classifier_name)  # Name of the best classifier\n",
    "print(\"Best Classifier Details:\", ai1.best_classifier)  # Details about the best classifier\n",
    "print(\"Classifier Predictor:\", ai1.predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed73832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96cb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa705085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6443",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
